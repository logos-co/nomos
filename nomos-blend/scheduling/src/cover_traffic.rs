use core::{
    num::NonZeroU64,
    pin::Pin,
    task::{Context, Poll},
};
use std::collections::HashSet;

use futures::{Stream, StreamExt as _};
use tracing::{debug, trace};

use crate::message_scheduler::round_info::Round;

const LOG_TARGET: &str = "blend::scheduling::cover";

/// A scheduler for cover messages that can yield a new cover message when
/// polled, as per the specification.
pub struct SessionCoverTraffic<Rng, RoundClock> {
    /// The clock ticking at the beginning of each new round.
    round_clock: RoundClock,
    /// The pre-computed set of rounds that will result in a cover message
    /// generated.
    // TODO: This set is actually not really needed. We can achieve the same result by simply
    // tracking how many cover messages we still have to emit, and how many rounds are left until
    // the end of the session. Every data message would decrease the number of cover messages to
    // emit. So we can remove this in the future, although it will get a bit trickier to test since
    // behavior would become probabilistic and not deterministic anymore.
    scheduled_message_rounds: HashSet<Round>,
    /// The count of data messages generated by the node that have not yet been
    /// accounted for by the scheduler.
    ///
    /// This is decreased every time this scheduler should emit a new cover
    /// message, but does not.
    unprocessed_data_messages: usize,
    /// The RNG used to compute whether a cover message should be released if
    /// there's unprocessed messages.
    rng: Rng,
}

impl<Rng, RoundClock> SessionCoverTraffic<Rng, RoundClock>
where
    Rng: rand::Rng,
{
    /// Initialize the scheduler with the required details.
    pub fn new(
        Settings {
            additional_safety_intervals,
            expected_intervals_per_session,
            rounds_per_interval,
            message_count,
        }: Settings,
        mut rng: Rng,
        round_clock: RoundClock,
    ) -> Self {
        let total_intervals = expected_intervals_per_session
            .get()
            .checked_add(additional_safety_intervals)
            .expect("Overflow when calculating total intervals per session.");
        let total_rounds = total_intervals
            .checked_mul(rounds_per_interval.get())
            .expect("Overflow when calculating total rounds per session.");
        debug!(target: LOG_TARGET, "Creating new cover message scheduler with {total_rounds} total rounds.");

        let scheduled_message_rounds =
            schedule_message_rounds(message_count, total_rounds, &mut rng);
        Self {
            round_clock,
            scheduled_message_rounds,
            unprocessed_data_messages: 0,
            rng,
        }
    }

    /// Consider the given round a release round if ALL of the following
    /// conditions are true:
    /// * The round is a pre-scheduled release round AND
    ///     * There is no unprocessed data message OR
    ///     * The random flip coin returns a value above the calculated
    ///       threshold, which is given by the number of unprocessed data
    ///       messages / the number of cover messages yet to release.
    fn consume_round(&mut self, round: &Round) -> bool {
        let current_scheduled_messages_count = self.scheduled_message_rounds.len();
        // No need to consume a data message quota because this is not a release round.
        if self.scheduled_message_rounds.is_empty() || !self.scheduled_message_rounds.remove(round)
        {
            return false;
        }
        if self.unprocessed_data_messages == 0 {
            return true;
        }

        // Instead of randomly removing an item from the set of pre-computed rounds,
        // which is not efficient for the data structure we are using, we instead resort
        // to using a coin flip to decide whether the next scheduled cover message
        // should be released. The probability of the cover message being released is
        // directly proportional to the number of cover messages yet to release, and
        // inversely proportional to the number of data messages that have not yet been
        // accounted for.
        let should_skip = {
            // Threshold will be in the range (0, unprocessed_data_messages], since we
            // checked that `unprocessed_data_messages` is not `0`, and that
            // `scheduled_message_rounds` is not empty, hence no side of the fraction can be
            // `0`.
            let threshold =
                self.unprocessed_data_messages as f64 / current_scheduled_messages_count as f64;
            self.rng.gen_range(0f64..=1f64) <= threshold
        };
        // If we are not emitting a cover message because of an unprocessed data
        // message, "burn" one quota.
        if should_skip {
            self.unprocessed_data_messages = self.unprocessed_data_messages.saturating_sub(1);
            trace!(target: LOG_TARGET, "Pre-schedule release skipped because of data message.");
        }
        !should_skip
    }
}

impl<Rng, RoundClock> SessionCoverTraffic<Rng, RoundClock> {
    #[cfg(test)]
    pub const fn with_test_values(
        round_clock: RoundClock,
        scheduled_message_rounds: HashSet<Round>,
        rng: Rng,
        unprocessed_data_messages: usize,
    ) -> Self {
        Self {
            round_clock,
            scheduled_message_rounds,
            unprocessed_data_messages,
            rng,
        }
    }

    #[cfg(test)]
    pub const fn unprocessed_data_messages(&self) -> usize {
        self.unprocessed_data_messages
    }

    /// Notify the scheduler that a new data message has been queued and will be
    /// released in the next round, which will result in one of the unscheduled
    /// cover messages from now to the end of the session to be randomly
    /// skipped.
    pub fn notify_new_data_message(&mut self) {
        self.unprocessed_data_messages = self
            .unprocessed_data_messages
            .checked_add(1)
            .expect("Overflow when incrementing unprocessed data messages.");
        debug!(target: LOG_TARGET, "New data message event registered. Unprocessed messages count: {}", self.unprocessed_data_messages);
    }
}

impl<Rng, RoundClock> Stream for SessionCoverTraffic<Rng, RoundClock>
where
    RoundClock: Stream<Item = Round> + Unpin,
    Rng: rand::Rng + Unpin,
{
    type Item = ();

    fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {
        let new_round = match self.round_clock.poll_next_unpin(cx) {
            Poll::Ready(Some(new_round)) => new_round,
            Poll::Ready(None) => return Poll::Ready(None),
            Poll::Pending => return Poll::Pending,
        };

        // If a new cover message is scheduled...
        if self.consume_round(&new_round) {
            debug!(target: LOG_TARGET, "Emitting new cover message for round {new_round}");
            return Poll::Ready(Some(()));
        }
        debug!(target: LOG_TARGET, "Not a pre-scheduled emission for round {new_round}.");
        // Awake to trigger a new round clock tick.
        cx.waker().wake_by_ref();
        Poll::Pending
    }
}

/// Pre-compute the rounds that will contain a cover message, given the amount
/// of messages to generate and the total number of rounds.
fn schedule_message_rounds<Rng>(
    mut total_message_count: u64,
    total_round_count: u64,
    rng: &mut Rng,
) -> HashSet<Round>
where
    Rng: rand::Rng,
{
    let mut scheduled_message_rounds = HashSet::with_capacity(total_message_count as usize);
    trace!(target: LOG_TARGET, "Generating {total_message_count} cover message slots.");
    // We are running a loop that assumes the sample space is larger than the number
    // of items we need to generate. If this assumption is not enforced, we end up
    // in a infinite loop.
    assert!(
        total_round_count >= total_message_count,
        "Cannot generate more messages than the available sample space. Total rounds to sample from {total_round_count}. Total messages to generate {total_message_count}."
    );

    while total_message_count > 0 {
        let random_round = rng.gen_range(0..total_round_count);
        if scheduled_message_rounds.insert(u128::from(random_round).into()) {
            total_message_count -= 1;
        } else {
            trace!(target: LOG_TARGET, "Random round generation yielded an already occupied round. Retrying...");
        }
    }
    scheduled_message_rounds
}

/// The settings to initialize the cover message scheduler.
#[derive(Debug, Clone, Copy)]
pub struct Settings {
    /// The number of intervals to use as the safety buffer in case of longer
    /// sessions, as per the spec.
    pub additional_safety_intervals: u64,
    /// The number of expected intervals per session.
    pub expected_intervals_per_session: NonZeroU64,
    /// The number of rounds per interval.
    pub rounds_per_interval: NonZeroU64,
    /// The maximum number of messages to generate in this session, before
    /// accounting for any generated data messages.
    pub message_count: u64,
}

#[cfg(test)]
mod tests {
    use core::task::{Context, Poll};
    use std::collections::HashSet;

    use futures::{StreamExt as _, io::empty, task::noop_waker_ref};
    use rand::rngs::OsRng;
    use tokio_stream::iter;

    use crate::cover_traffic::SessionCoverTraffic;

    #[tokio::test]
    async fn no_emission_on_empty_schedule() {
        let mut scheduler = SessionCoverTraffic {
            round_clock: iter([0u128]).map(Into::into),
            scheduled_message_rounds: HashSet::default(),
            unprocessed_data_messages: 0,
            rng: OsRng,
        };
        let mut cx = Context::from_waker(noop_waker_ref());

        assert_eq!(scheduler.poll_next_unpin(&mut cx), Poll::Pending);
    }

    #[tokio::test]
    async fn no_emission_on_unscheduled_round() {
        let mut scheduler = SessionCoverTraffic {
            round_clock: iter([0u128]).map(Into::into),
            scheduled_message_rounds: HashSet::from_iter([1u128.into()]),
            unprocessed_data_messages: 0,
            rng: OsRng,
        };
        let mut cx = Context::from_waker(noop_waker_ref());

        assert_eq!(scheduler.poll_next_unpin(&mut cx), Poll::Pending);
    }

    #[tokio::test]
    async fn emission_on_scheduled_round_without_processed_messages() {
        let mut scheduler = SessionCoverTraffic {
            round_clock: iter([0u128]).map(Into::into),
            scheduled_message_rounds: HashSet::from_iter([0u128.into()]),
            unprocessed_data_messages: 0,
            rng: OsRng,
        };
        let mut cx = Context::from_waker(noop_waker_ref());

        assert_eq!(scheduler.poll_next_unpin(&mut cx), Poll::Ready(Some(())));
        // Check that the scheduled round has been removed from the set.
        assert!(!scheduler.scheduled_message_rounds.contains(&0u128.into()));
    }

    #[tokio::test]
    async fn no_emission_on_scheduled_round_with_single_unprocessed_message() {
        let mut scheduler = SessionCoverTraffic {
            round_clock: iter([0u128]).map(Into::into),
            scheduled_message_rounds: HashSet::from_iter([0u128.into()]),
            unprocessed_data_messages: 1,
            rng: OsRng,
        };
        let mut cx = Context::from_waker(noop_waker_ref());

        assert_eq!(scheduler.poll_next_unpin(&mut cx), Poll::Pending);
        // Check that the scheduled round has been removed from the set.
        assert!(!scheduler.scheduled_message_rounds.contains(&0u128.into()));
        // Check that the number of processed messages has been decremented.
        assert_eq!(scheduler.unprocessed_data_messages, 0);
    }

    #[tokio::test]
    async fn no_emission_on_scheduled_round_with_multiple_unprocessed_messages() {
        let mut scheduler = SessionCoverTraffic {
            round_clock: iter([0u128, 1u128, 2u128]).map(Into::into),
            scheduled_message_rounds: HashSet::from_iter([
                0u128.into(),
                1u128.into(),
                2u128.into(),
            ]),
            unprocessed_data_messages: 2,
            rng: OsRng,
        };
        let mut cx = Context::from_waker(noop_waker_ref());

        // We have a random factor, so we can't test step-by-step, but we can say that
        // after polling the stream 3 times, we should have a single cover message
        // generated.
        let cover_message_count = (0u8..=2).fold(0u8, |count, _| {
            if scheduler.poll_next_unpin(&mut cx) == Poll::Ready(Some(())) {
                count + 1
            } else {
                count
            }
        });

        // Out of `3` scheduled release rounds, only one will yield a cover message,
        // since there's `2` unprocessed data messages.
        assert_eq!(cover_message_count, 1);
        // Check that the number of processed messages has been consumed.
        assert_eq!(scheduler.unprocessed_data_messages, 0);
    }

    #[test]
    fn notify_new_data_message_without_scheduled_rounds() {
        let mut scheduler = SessionCoverTraffic {
            round_clock: empty(),
            scheduled_message_rounds: HashSet::new(),
            unprocessed_data_messages: 0,
            rng: OsRng,
        };
        scheduler.notify_new_data_message();
        assert_eq!(scheduler.unprocessed_data_messages, 1);
    }

    #[test]
    fn notify_new_data_message_with_scheduled_rounds() {
        let mut scheduler = SessionCoverTraffic {
            round_clock: empty(),
            scheduled_message_rounds: HashSet::from_iter([1u128.into()]),
            unprocessed_data_messages: 0,
            rng: OsRng,
        };
        scheduler.notify_new_data_message();
        assert_eq!(scheduler.unprocessed_data_messages, 1);
    }
}
